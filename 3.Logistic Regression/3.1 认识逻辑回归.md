# 认识逻辑回归

解决的问题：`分类问题——把“像”还是“不像”说清楚`

想象你早上走进办公室，前台小姐姐递给你一叠简历，让你“把可能合适的候选人挑出来”。  
你并不会给每份简历打一个 0～100 的“能力分”，而是直接贴上“约”或“不约”的小纸条——这就是**分类**：输出的是离散的“标签”，而不是连续的数值。

## 1. 从生活到数据：分类无处不在
- 邮箱里突然弹出的“垃圾邮件”提示  
- 手机相册自动把“喵星人”和“汪星人”分开  
- 银行短信提示“疑似盗刷”  
- 医院体检报告上的“阴性 / 阳性”  

它们背后都藏着一个共同问题：如何把“像”还是“不像”说清楚？  
答案正是**分类算法**——让计算机像人一样“贴纸条”。

## 2. 分类 vs. 回归：一张图看懂区别
| 任务类型 | 输出结果 | 例子 |
| --- | --- | --- |
| 回归 | 连续数字 | 房价 327.5 万、温度 23.8 ℃ |
| 分类 | 离散标签 | 邮件“垃圾”/“正常”、肿瘤“良性”/“恶性” |

一句话：**回归预测“多少”，分类判断“哪类”**。

## 3. 监督学习：老师先给你“标准答案”
分类属于**监督学习**。就像考试前老师发了一本“带答案的习题册”——每封邮件都提前告诉你“这是垃圾”或“这不是垃圾”。  
模型反复“刷题”，学会把特征与标签对应起来，再去“考试”（预测新邮件）。  
没有这些“标准答案”，就成了**无监督学习**，只能“盲猜”聚类，效果往往大打折扣。

## 4. 二分类：一切从“是 / 否”开始
最基础也最经典的场景是**二分类**（Binary Classification）：  
- 邮件：垃圾？正常？  
- 交易：欺诈？正常？  
- 片子：肺炎？健康？  

别小看“只有两个选项”，它覆盖了 80% 以上的业务痛点。  
逻辑回归正是解决二分类问题的“老兵”：  
1. 先算出一封邮件“像垃圾”的概率——比如 0.87；  
2. 再跟“阈值”比较——超过 0.5 就贴上“垃圾”纸条；  
3. 最后还能告诉你“为什么被拦截”——权重最高的词是“中奖”“点击”“汇款”，解释性满满。

> 二分类的分类流程
> 先定义一个类别为类型1，其余剩下的数据为类型2，只需要分类一次，就可以将所有数据分类完毕

## 5. 多分类：“一对多”还是“一对一”？

当类别超过两个时，二分类的“是/否”套路就要升级。主流打法有两套：

| 策略 | 简称 | 核心思想 | 训练次数 | 预测规则 |
| --- | --- | --- | --- | --- |
| 一对多 | OvR（One-vs-Rest） | 每次把某一类当“正”，其余全部当“负” | n 次 | 选“正”概率最高的那一类 |
| 一对一 | OvO（One-vs-One） | 每两个类单独掐一架 | n(n−1)/2 次 | 投票制，得票最多者胜出 |

> 多分类流程（以 OvR 为例）
> 1. 先把类别 A 当正类，其余 B/C/D 统统当负类，训练第 1 个逻辑回归；
> 2. 再把类别 B 当正类，其余 A/C/D 当负类，训练第 2 个逻辑回归；
> 3. 重复 n 次，得到 n 个模型；
> 4. 来了一条新数据，让 n 个模型各自输出“自己是正类”的概率，谁最大就把数据判给谁。

OvR 胜在简单快速，scikit-learn 默认就用它；OvO 虽然模型多，但每次训练只用两个类的数据，反而适合类别多、样本大的场景。  
逻辑回归借助这两种“组合拳”，就能把“像/不像”的二分类智慧，平滑地扩展到“猫/狗/兔”甚至更多类别的世界。

## 5. 小结：一句话记住分类
分类就是**在已知答案的“习题册”里练出火眼金睛，再去新世界里贴对标签**。  
逻辑回归则是这套“火眼金睛”里最轻便、最透明、最容易上手的那副眼镜。接下来，我们就拆开这副眼镜，看看它是如何把概率算得又快又准，还能让业务同事心服口服。
