# 逻辑回归求解
## 1. 从“线性”到“概率”——二分类模型假设
逻辑回归虽然名字带“回归”，但它解决的是**二分类**问题。  
我们希望：  
输入一个样本 x，输出它属于正类（y=1）的概率 P(y=1|x)。  

线性回归直接输出实数，范围 (−∞,+∞)，而概率必须在 [0,1]。  
于是我们把线性部分 z=wᵀx+b 塞进**Sigmoid 函数**里：

$
\hat{p}=σ(z)=\frac{1}{1+e^{-z}}=\frac{1}{1+e^{-(w^\top x+b)}}
$

- 当 z→+∞，σ(z)→1；当 z→−∞，σ(z)→0。  
- 决策规则：若 σ(z)≥0.5 判为 1，否则判为 0。  
- 几何意义：在特征空间画一条“超平面”，平面两侧分别对应概率 0.5 的两侧。

## 2. 损失函数——衡量“单样本”预测好坏
对单个样本 (xᵢ,yᵢ)，我们希望：

- 若真实 yᵢ=1，预测概率 σ(zᵢ) 越接近 1 越好；  
- 若 yᵢ=0，σ(zᵢ) 越接近 0 越好。

把两种情形合并，得到**对数损失**（又叫交叉熵损失）：

$
\mathcal{L}(\hat{y},y)=−[y\log\hat{y}+(1−y)\log(1−\hat{y})]
$

- yᵢ=1 时，第二项消失；yᵢ=0 时，第一项消失。  
- 当预测错误且置信度高时，损失→+∞，模型会被“狠狠惩罚”。

## 3. 代价函数——衡量“整体”拟合程度
为了衡量算法在全部训练样本上的表现如何，我们需要定义一个算法的代价函数，算法的代价函数是 `对m个样本的损失函数求和然后除以m`。
把 m 个样本的损失取平均，再加上 **正则化** `防止过拟合`，得到最终要最小化的目标：

$
J(w)=\frac{1}{m}\sum_{i=1}^m\mathcal{L}_i =  \frac{1}{m}\sum_{i=1}^m(−[y^{i}\log\hat{y}^{i}+(1−y^{i})\log(1−\hat{y}^{i})])
$

- λ=0 时退化为无正则；λ 越大，模型越“保守”，权重越接近 0。  
- 注意：偏置项 b 通常不加惩罚。

## 4. 逻辑回归求解——“最大似然”
目标：找到一组参数 $w$（和 $b$），使得“观测到的训练样本”出现的概率最大——这就是**最大似然估计**（MLE）的核心思想。  
思路：把每个样本的预测概率写成关于 $w$ 的函数，再把它们连乘起来得到“整体可信度”——似然函数；接着对似然函数取对数、加负号，就得到我们熟悉的**交叉熵损失**；最后最小化这个损失，就等价于最大化似然。

求解过程：  
1. 似然函数回顾  
   对单样本 $(x^{(i)}, y^{(i)})$，逻辑回归给出的概率模型是  
   $$P(y^{(i)}|x^{(i)}; w, b)=
   \begin{cases}
   h_\theta(x^{(i)}),   & \text{若 } y^{(i)}=1 \\[6pt]
   1-h_\theta(x^{(i)}),& \text{若 } y^{(i)}=0
   \end{cases}$$
   其中 $h_\theta(x)=\sigma(w^\top x+b)$。把两种情况合写成一个紧凑的表达式：
   $$P(y^{(i)}|x^{(i)}; w, b)=h_\theta(x^{(i)})^{y^{(i)}}\cdot\bigl(1-h_\theta(x^{(i)})\bigr)^{1-y^{(i)}}$$

   对 $m$ 条独立同分布的样本，整体似然就是连乘：
   $$L(w, b)=\prod_{i=1}^m P(y^{(i)}|x^{(i)}; w, b)
            =\prod_{i=1}^m h_\theta(x^{(i)})^{y^{(i)}}\cdot\bigl(1-h_\theta(x^{(i)})\bigr)^{1-y^{(i)}}$$

2. 对数似然——把“连乘”变“连加”  
   直接最大化 $L(w, b)$ 不好算，于是取对数，把乘积变求和：
   $$\ell(w, b)=\log L(w, b)
              =\sum_{i=1}^m\Bigl[y^{(i)}\log h_\theta(x^{(i)})+(1-y^{(i)})\log\bigl(1-h_\theta(x^{(i)})\bigr)\Bigr]$$

   注意：上式里每条样本的项，正好就是交叉熵损失的负值。也就是说
   $$\ell(w, b)=-\sum_{i=1}^m \mathcal{L}_i$$
   其中 $\mathcal{L}_i$ 是第 3 节里定义的“单样本对数损失”。

3. 最大化 ⇨ 最小化  
   我们要让 $\ell(w, b)$ 越大越好，等价于让“负对数似然”越小越好。于是定义代价函数：
   $$J(w, b)=-\frac{1}{m}\ell(w, b)
            =\frac{1}{m}\sum_{i=1}^m\Bigl[-y^{(i)}\log h_\theta(x^{(i)})-(1-y^{(i)})\log\bigl(1-h_\theta(x^{(i)})\bigr)\Bigr]$$
   这就是前面第 3 节给出的交叉熵代价函数。换句话说：  
   **最小化交叉熵损失 = 最大化似然函数**

4. 正则化补充  
   如果担心过拟合，再给似然“打个折”，即在代价函数里加上 L2 惩罚：
   $$J_{\text{reg}}(w, b)=J(w, b)+\frac{\lambda}{2m}\|w\|^2$$
   注意偏置 $b$ 通常不惩罚，让它自由调节整体基准。

5. 小结一句话  
   逻辑回归没有“最小二乘”那种闭式解，但好在它的负对数似然是**关于 $w$ 的凸函数**（证明略，可放心）。只要用梯度下降或牛顿法等通用优化器，就能稳稳地找到全局最优解。

## 5. 梯度下降求解——一步步“下山”
目标：找到最优参数 w 和 b，使代价函数 J 最小。  
思路：沿着**负梯度**方向一点点更新参数，就像蒙眼下山，每一步踩最陡的下坡。

### 5.1 计算梯度——“先拆再链”
我们先回忆两条核心公式：
1. 线性得分：$z_i = w^\top x_i + b$
2. Sigmoid 输出：$\hat{p}_i = \sigma(z_i) = \frac{1}{1+e^{-z_i}}$

代价函数（先忽略正则，稍后再加）：
$
J(w,b)=\frac{1}{m}\sum_{i=1}^m \Bigl[-y_i\log\hat{p}_i - (1-y_i)\log(1-\hat{p}_i)\Bigr]
$

#### ① 对权重 wⱼ 求偏导——“链式三件套”
把 $J$ 看成复合函数：$J \rightarrow \mathcal{L}_i \rightarrow \hat{p}_i \rightarrow z_i \rightarrow w_j$  
一步一步拆：

- 外层：$\frac{\partial \mathcal{L}_i}{\partial \hat{p}_i} = -\frac{y_i}{\hat{p}_i} + \frac{1-y_i}{1-\hat{p}_i}$
- Sigmoid 导数：$\frac{\partial \hat{p}_i}{\partial z_i} = \hat{p}_i(1-\hat{p}_i)$  （经典恒等式）
- 线性部分：$\frac{\partial z_i}{\partial w_j} = x_{i,j}$

三链相乘：
$
\frac{\partial \mathcal{L}_i}{\partial w_j}
= \left(-\frac{y_i}{\hat{p}_i} + \frac{1-y_i}{1-\hat{p}_i}\right)\cdot \hat{p}_i(1-\hat{p}_i)\cdot x_{i,j}
= (\hat{p}_i - y_i)\,x_{i,j}
$

把 m 个样本累加再平均，得到：
$
\frac{\partial J}{\partial w_j}=\frac{1}{m}\sum_{i=1}^m(\hat{p}_i - y_i)\,x_{i,j}
$

#### ② 对偏置 b 求偏导
同理，$\frac{\partial z_i}{\partial b}=1$，其余链条不变，于是：
$
\frac{\partial J}{\partial b}=\frac{1}{m}\sum_{i=1}^m(\hat{p}_i - y_i)
$

#### ③ 加入 L2 正则——“给权重戴紧箍”
若使用 L2 正则，代价函数变为：
$
J_{\text{reg}}(w,b)=J(w,b)+\frac{\lambda}{2m}\|w\|^2
$

对 wⱼ 的梯度额外多一项：
$
\frac{\partial J_{\text{reg}}}{\partial w_j}=\underbrace{\frac{1}{m}\sum_{i=1}^m(\hat{p}_i - y_i)\,x_{i,j}}_{\text{数据误差}} + \underbrace{\frac{\lambda}{m}w_j}_{\text{权重惩罚}}
$

偏置 b 依旧不加正则，梯度保持不变。

### 5.2 更新规则——“批量梯度下降”
重复以下两步直到收敛（可设置最大迭代次数或容忍误差）：

1. 计算所有样本的梯度：
   $
   \begin{aligned}
   \frac{\partial J_{\text{reg}}}{\partial w_j} &= \frac{1}{m}\sum_{i=1}^m(\hat{p}_i - y_i)\,x_{i,j} + \frac{\lambda}{m}w_j \\
   \frac{\partial J}{\partial b} &= \frac{1}{m}\sum_{i=1}^m(\hat{p}_i - y_i)
   \end{aligned}
   $

2. 同时更新每个参数（α 为学习率）：
   $
   \begin{aligned}
   w_j &\leftarrow w_j - \alpha\,\frac{\partial J_{\text{reg}}}{\partial w_j} \\
   b &\leftarrow b - \alpha\,\frac{\partial J}{\partial b}
   \end{aligned}
   $

#### 直观理解
- 若模型对正类样本预测概率偏低（$\hat{p}_i < y_i=1$），梯度为负，w 往“增加得分”方向走。  
- 若对负类样本预测概率偏高（$\hat{p}_i > y_i=0$），梯度为正，w 往“降低得分”方向走。  
- 正则项则像“橡皮筋”，把过大的权重往回拉，防止模型“ memorize”训练集。

### 4.3 代码片段

1. Sigmod 函数
```python
import numpy as np

def sigmoid(z):
   """
   Sigmoid 函数
   参数：
   - z：任意实数
   返回值：
   - 0 到 1 之间的实数
   """
   return 1 / (1 + np.exp(-z))
```

2. 代价函数
$ J(w) = -\frac{1}{m}\sum_{i=1}^{m}(y^{(i)}log(h(x^{(i)})) + (1 - y^{(i)})log(1 - h(x^{(i)})))$

```python
import numpy as np

def cost(X, y, w):
   """
   代价函数
   参数：
   - X：样本矩阵
   - y：标签向量
   - w：权重向量
   返回值：
   - 代价函数值
   """
   # 将输入的权重向量 w 转换为 NumPy 矩阵，方便后续矩阵运算
   w = np.matrix(w)
   # 将输入的样本矩阵 X 转换为 NumPy 矩阵，确保维度一致
   X = np.matrix(X)
   # 将输入的标签向量 y 转换为 NumPy 矩阵，便于广播计算
   y = np.matrix(y)

   # 计算交叉熵损失的第一部分：-y * log(sigmoid(X * w^T))
   # 对应真实标签为 1 的样本的负对数似然
   frist = np.multiply(-y, np.log(sigmoid(X * w.T)))

   # 计算交叉熵损失的第二部分：(1 - y) * log(1 - sigmoid(X * w^T))
   # 对应真实标签为 0 的样本的负对数似然
   # 注意：这里原代码笔误写成 w.t，已修正为 w.T，保证矩阵转置正确
   second = np.multiply((1 - y), np.log(1 - sigmoid(X * w.T)))

   # 将两部分损失相加后求平均，得到整个训练集的平均代价
   # 除以样本数 len(X) 实现求平均
   return np.sum(first - second) / (len(X))
```